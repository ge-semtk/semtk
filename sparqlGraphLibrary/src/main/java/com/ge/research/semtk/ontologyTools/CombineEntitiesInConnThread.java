package com.ge.research.semtk.ontologyTools;

import java.util.ArrayList;
import java.util.Arrays;
import java.util.HashSet;
import java.util.Hashtable;

import com.ge.research.semtk.auth.HeaderTable;
import com.ge.research.semtk.auth.ThreadAuthenticator;
import com.ge.research.semtk.belmont.AutoGeneratedQueryTypes;
import com.ge.research.semtk.belmont.Node;
import com.ge.research.semtk.belmont.NodeDeletionTypes;
import com.ge.research.semtk.belmont.NodeGroup;
import com.ge.research.semtk.belmont.ValueConstraint;
import com.ge.research.semtk.edc.JobTracker;
import com.ge.research.semtk.edc.client.ResultsClient;
import com.ge.research.semtk.resultSet.Table;
import com.ge.research.semtk.sparqlToXLib.SparqlToXLibUtil;
import com.ge.research.semtk.sparqlX.SparqlConnection;
import com.ge.research.semtk.sparqlX.SparqlToXUtils;
import com.ge.research.semtk.utility.LocalLogger;

/**
 * Process a table full of requests to combine entities by lookup
 * @author 200001934
 *
 */
public class CombineEntitiesInConnThread extends Thread {
	private JobTracker tracker;
	private ResultsClient resultsClient;
	private String jobId;
	private OntologyInfo oInfo;
	private SparqlConnection conn;
	private String sameAsTypeUri;
	private String targetPropUri;
	private String duplicatePropUri;
	private ArrayList<String> deletePredicatesFromTarget;
	private ArrayList<String> deletePredicatesFromDuplicate;
	private Table errorTab;
	private HeaderTable headerTable = null;
	private RestrictionChecker checker = null;


	/**
	 * Create a thread for combining entities by querying instances of sameAsTypeUri
	 * which has properties targetPropUri and duplicatePropUri
	 * 
	 * Prechecks - but not perfectly, as things like loops are tricky to detect beforehand
	 * Combines
	 * Deletes instances of sameAsTypeUri
	 * 
	 * @param tracker
	 * @param resultsClient
	 * @param jobId
	 * @param oInfo
	 * @param conn
	 * @param sameAsTypeUri
	 * @param targetPropUri
	 * @param duplicatePropUri
	 * @param deletePredicatesFromTarget - list of predicates to delete from target before merging
	 * @param deletePredicatesFromDuplicate - list of predicates to delete from duplicate 
	 * @throws Exception - catch all
	 */
	public CombineEntitiesInConnThread(JobTracker tracker, ResultsClient resultsClient, String jobId, 
			OntologyInfo oInfo, SparqlConnection conn,
			String sameAsTypeUri,
			String targetPropUri,
			String duplicatePropUri, 
			ArrayList<String> deletePredicatesFromTarget,
			ArrayList<String> deletePredicatesFromDuplicate) throws SemtkUserException, Exception {
		this.tracker = tracker;
		this.resultsClient = resultsClient;
		this.jobId = jobId;
		this.tracker.createJob(this.jobId);
		this.oInfo = oInfo;
		this.conn = conn;
		this.sameAsTypeUri = sameAsTypeUri;
		this.targetPropUri = targetPropUri;
		this.duplicatePropUri = duplicatePropUri;
		this.headerTable = ThreadAuthenticator.getThreadHeaderTable();
		this.checker = new RestrictionChecker(conn, oInfo);

		this.errorTab = new Table(new String [] { "error" });
		
		CombineEntitiesWorker.replacePropertyAbbrev(this.deletePredicatesFromTarget);
		CombineEntitiesWorker.replacePropertyAbbrev(this.deletePredicatesFromDuplicate);
		
		// Check the properties in the table to make sure they're legal
		if (this.oInfo.getClass(this.sameAsTypeUri) == null) {
			throw new SemtkUserException("Can't find class in model: " + this.sameAsTypeUri);
		}
		if (this.oInfo.getProperty(this.targetPropUri) == null && !this.duplicatePropUri.equals(SparqlToXLibUtil.TYPE_PROP)) {
			throw new SemtkUserException("Can't find target property in model: " + this.targetPropUri);
		}
		
		if (this.oInfo.getProperty(this.duplicatePropUri) == null && !this.duplicatePropUri.equals(SparqlToXLibUtil.TYPE_PROP)) {
			throw new SemtkUserException("Can't find duplicate property in model: " + this.duplicatePropUri);
		}

	}
	
	
	public void run() {
		ThreadAuthenticator.authenticateThisThread(this.headerTable);
		
		try {
			// query retrieves SameAs that are eligible for next batch
			this.tracker.createJob(this.jobId);
			
			this.runPrecheck();
			
			// stop now if any errors have occurred
			if (this.errorTab.getNumRows() > 0) {
				this.resultsClient.execStoreTableResults(this.jobId, this.errorTab);
				this.tracker.setJobFailure(this.jobId, "Errors during pre-check.  No merging was attempted.");
				return;
			}

			
		} catch (Exception e) {
			LocalLogger.logToStdErr("Internal Error during precheck");
			LocalLogger.printStackTrace(e);
		}
		
		
		try {
			String nextBatchQuery = this.generateGetNextSameAsBatchSparql();
			int numSameAs = this.countSameAs();
			ArrayList<String> sameAsUriList = new ArrayList<String>();
			int recordsProcessed = 0;
			Table batchTable = null;
			
			HashSet<Triple> insertTriples = new HashSet<Triple>();
			HashSet<Triple> deleteTriples = new HashSet<Triple>();
			int TRIPLE_BATCH = 50;
			
			// preform the combining in batches so that order is correct
			do {
				batchTable = this.conn.getDefaultQueryInterface().executeQueryToTable(nextBatchQuery);
				
				// do the work
				for (int i=0; i < batchTable.getNumRows(); i++) {
					
					CombineEntitiesWorker w =  new CombineEntitiesWorker(
							this.oInfo, this.conn, 
							batchTable.getCell(i, "target"), batchTable.getCell(i, "duplicate"),
							batchTable.getCell(i, "target_types").split(" "), batchTable.getCell(i, "duplicate_types").split(" "), 
							this.deletePredicatesFromTarget, this.deletePredicatesFromDuplicate,
							checker
							);
					w.generateCombineTriples();
					insertTriples.addAll(w.getInsertTriples());
					deleteTriples.addAll(w.getDeleteTriples());
					sameAsUriList.add(batchTable.getCell(i, "same_as"));
					recordsProcessed += 1;
					
					
					if (insertTriples.size() > TRIPLE_BATCH || deleteTriples.size() > TRIPLE_BATCH) {
						// perform queries when there are enough triples
						this.conn.getDefaultQueryInterface().executeQueryAndConfirm(
								SparqlToXLibUtil.generateInsertTriples(this.conn, insertTriples)
								);
						insertTriples.clear();
						
						this.conn.getDefaultQueryInterface().executeQueryAndConfirm(
								SparqlToXLibUtil.generateDeleteTriples(this.conn, deleteTriples)
								);
						deleteTriples.clear();
						
						this.conn.getDefaultQueryInterface().executeQueryAndConfirm(
								SparqlToXLibUtil.generateDeleteUris(this.conn, sameAsUriList)
								);
						sameAsUriList.clear();
						
						int percent = Math.min(99, 50 + 50 * recordsProcessed / numSameAs);
						this.tracker.setJobPercentComplete(this.jobId, percent);
					}
				}
				
				// perform queries for left overs
				this.conn.getDefaultQueryInterface().executeQueryAndConfirm(
						SparqlToXLibUtil.generateInsertTriples(this.conn, insertTriples)
						);
				insertTriples.clear();
				
				this.conn.getDefaultQueryInterface().executeQueryAndConfirm(
						SparqlToXLibUtil.generateDeleteTriples(this.conn, deleteTriples)
						);
				deleteTriples.clear();
				
				this.conn.getDefaultQueryInterface().executeQueryAndConfirm(
						SparqlToXLibUtil.generateDeleteUris(this.conn, sameAsUriList)
						);
				sameAsUriList.clear();		
				
			} while (batchTable.getNumRows() > 0);

			if (recordsProcessed == numSameAs) {
				// success
				this.tracker.setJobSuccess(this.jobId, String.format("Combined %d pairs of entities.", recordsProcessed));
			} else {
				
				// query leftover SameAs and fail
				Table t = this.conn.getDefaultQueryInterface().executeQueryToTable(
						this.generateGetAllSameAsSparql());
				if (t.getNumRows() != 0) {
					for (int i=0; i < t.getNumRows(); i++) {
						this.errorTab.addRow(new String [] {
								String.format("Remains after merging: %s", t.getCell(i, "same_as"))
							});
					}
				}
				this.resultsClient.execStoreTableResults(this.jobId, this.errorTab);
				this.tracker.setJobFailure(this.jobId, "Invalid SameAs instances (possibly loops) remain after merging");
				
			}

		} catch (Exception e) {
			LocalLogger.printStackTrace(e);
			try {
				// Exceptions are reported via the async job status mechanism
				this.tracker.setJobFailure(this.jobId, "Error during merge.  Incomplete merge occurred. \n" + e.getMessage());

			} catch (Exception ee) {
				// Bail from total mess with log messages and a stranded job
				LocalLogger.logToStdErr("CombineEntitiesTableThread stranded a job due to another exception during setJobFailure()");
				LocalLogger.printStackTrace(ee);
			}
		}
	}

	/**
	 * Run all pre-checking. 
	 * Group pre-checks:
	 * 		no object can be duplicate to two different primaries
	 *      no sameAs can have target==duplicate
	 *      cardinality of duplicate and target is exactly 1
	 * Individual pre-checks:
	 * 	    defined by CombineEntitiesWorker
	 * 
	 * Note that some kinds problems that should only result in left-over SameAs are not caught:
	 *       loops
	 *       
	 * Puts errors into this.errorTab
	 * @throws Exception - 
	 */
	private void runPrecheck() throws Exception {
		Table t;
		
		// precheck no object is duplicate to 2 different sameAs
		t = this.conn.getDefaultQueryInterface().executeQueryToTable(
				this.generateGetBadSameAsDuplicates());
		if (t.getNumRows() != 0) {
			for (int i=0; i < t.getNumRows(); i++) {
				this.errorTab.addRow(new String [] {
						String.format("Object is duplicate to to different targets: %s", t.getCell(i, "duplicate"))
					});
			}
		}
		this.tracker.setJobPercentComplete(this.jobId, 1 / 8);
		
		// precheck no object is target==duplicate
		t = this.conn.getDefaultQueryInterface().executeQueryToTable(
				this.generateGetBadSameAsDupEqTarget());
		if (t.getNumRows() != 0) {
			for (int i=0; i < t.getNumRows(); i++) {
				this.errorTab.addRow(new String [] {
						String.format("SameAs object has target==duplicate. sameAs: %s object: %s", t.getCell(i, "same_as1"), t.getCell(i, "object"))
				});
			}
		}
		this.tracker.setJobPercentComplete(this.jobId, 2 / 8);
		
		// precheck no missing or multiple target or duplicate
		t = this.conn.getDefaultQueryInterface().executeQueryToTable(
				this.generateGetBadSameCardinalityErr());
		if (t.getNumRows() != 0) {
			for (int i=0; i < t.getNumRows(); i++) {
				this.errorTab.addRow(new String [] {
						String.format("SameAs does not have exactly 1 target and 1 duplicate: %s", t.getCell(i, "same_as1"))
				});
			}
		}
		this.tracker.setJobPercentComplete(this.jobId, 3 / 8);
		
		// Worker checks individual things like type
		t = this.conn.getDefaultQueryInterface().executeQueryToTable(this.generateGetCombiningDiffTypes());
	
		for (int i=0; i < t.getNumRows(); i++) {
			CombineEntitiesWorker worker = new CombineEntitiesWorker(oInfo, conn, 
					t.getCell(i, "target"), t.getCell(i, "duplicate"), 
					this.deletePredicatesFromTarget, this.deletePredicatesFromDuplicate,
					checker);
			try {
				worker.preCheck();
			} catch (SemtkUserException e) {
				this.errorTab.addRow(new String [] {e.getMessage()});
			}
		}
		this.tracker.setJobPercentComplete(this.jobId, 4 / 8);
	}
	
	private void setJobPercentComplete(int percent) {
		try {
			this.tracker.setJobPercentComplete(this.jobId, percent);
		} catch (Exception e) {}
	}
	
	/**
	 * Count the number of this.sameAsTypeUri instances in the 
	 * @return
	 * @throws Exception
	 */
	private int countSameAs() throws Exception {
		NodeGroup ng = new NodeGroup();
		ng.setSparqlConnection(this.conn);
		
		Node n = ng.addNode(this.sameAsTypeUri, this.oInfo);
		n.setIsReturned(true);
		String sparql = ng.generateSparql(AutoGeneratedQueryTypes.COUNT, null, null, null);
		return this.conn.getDefaultQueryInterface().executeToTable(sparql).getCellAsInt(0, 0);
	}
	
	
	// TODO move queries to SparqlToXLibUtils
	
	/**
	 * Get SameAs that can be processed in next batch because duplicate has no other incoming
	 * Current SPARQL generation and nodegroups are not powerful enough to do this because:
	 * 	1. (issue #405) there is no FILTER NOT EXISTS 
	 *  2. (issue #406) Examples such as RACK SAME_AS with range of type THING generates very long VALUES clauses for types
	 *  3. (          ) Can't group by type
	 * @return
	 * @throws Exception
	 */
	private String generateGetNextSameAsBatchSparql() throws Exception {

		String query =  
				"select distinct ?same_as ?target ?duplicate (GROUP_CONCAT (?target_type ) as ?target_types)  (GROUP_CONCAT (?duplicate_type ) as ?duplicate_types)\n"
				+ SparqlToXLibUtil.generateSparqlFromOrUsing("", "FROM", this.conn, this.oInfo) + "\n"
				+ " where {\n"
				+ "     ?same_as a <" + this.sameAsTypeUri + "> .\n"
				+ "	    ?same_as <" + this.targetPropUri + "> ?target .\n"
				+ "     ?same_as <" + this.duplicatePropUri + "> ?duplicate.\n"
				+ "     ?target a ?target_type.\n"
				+ "     ?duplicate a ?duplicate_type.\n"
				+ "     filter not exists {\n"
				+ "	        ?other1 <" + this.targetPropUri + "> ?duplicate.\n"
				+ "	        FILTER (?other1 != ?same_as) . \n"
				+ "	    }\n"
 				+ "     filter not exists {\n"
				+ "		    ?other2 <" + this.duplicatePropUri + "> ?duplicate.\n"
				+ "		    FILTER (?other2 != ?same_as) . \n"
				+ "	    }\n"
				+ "}\n"
				+ "GROUP BY ?same_as ?target ?duplicate";
			
		return query;
	}
	
	private String generateGetAllSameAsSparql() throws Exception {

		String query =  String.format(
				"select distinct ?same_as ?target ?duplicate\n"
				+ "%s\n"
				+ " where {\n"
				+ "     ?same_as a <%s> .\n"
				+ "	    ?same_as <%s> ?target .\n"
				+ "     ?same_as <%s> ?duplicate.\n"
				+ "}\n"
				+ "",
				SparqlToXLibUtil.generateSparqlFromOrUsing("", "FROM", this.conn, this.oInfo),
				this.sameAsTypeUri,
				this.targetPropUri, 
				this.duplicatePropUri
				);
				
		return query;
	}
	
	private String generateGetCombiningDiffTypes() throws Exception {

		String query = 
				"select distinct ?same_as ?target ?duplicate\n"
				+ SparqlToXLibUtil.generateSparqlFromOrUsing("", "FROM", this.conn, this.oInfo) + "\n"
				+ " where {\n"
				+ "	    ?same_as1 <" + this.targetPropUri + "> ?target .\n"
				+ "     ?same_as1 <" + this.duplicatePropUri + "> ?duplicate.\n"
				+ "     ?target a ?t1. \n"
				+ "     ?duplicate a ?t2. \n"
				+ "     filter (?t1 != ?t2).\n"
				+ "     ?same_as1 a <" + this.sameAsTypeUri + "> .\n"
				+ "}\n"
				;
		
				
		return query;
	}
	
	private String generateGetBadSameAsDuplicates() throws Exception {

		String query = 
				"select distinct ?same_as1 ?same_as2 ?duplicate\n"
				+ SparqlToXLibUtil.generateSparqlFromOrUsing("", "FROM", this.conn, this.oInfo) + "\n"
				+ " where {\n"
				+ "	    ?same_as1 <" + this.duplicatePropUri + "> ?duplicate .\n"
				+ "     ?same_as2 <" + this.duplicatePropUri + "> ?duplicate.\n"
				+ "     filter (?same_as2 != ?same_as1).\n"
				+ "     ?same_as1 a <" + this.sameAsTypeUri + "> .\n"
				+ "     ?same_as2 a <" + this.sameAsTypeUri + "> .\n"
				+ "}\n"
				;
				
		return query;
	}
	
	private String generateGetBadSameAsDupEqTarget() throws Exception {

		String query = 
				"select distinct ?same_as1 ?object\n"
				+ SparqlToXLibUtil.generateSparqlFromOrUsing("", "FROM", this.conn, this.oInfo) + "\n"
				+ " where {\n"
				+ "	    ?same_as1 <" + this.targetPropUri    + "> ?object .\n"
				+ "     ?same_as1 <" + this.duplicatePropUri + "> ?object.\n"
				+ "     ?same_as1 a <" + this.sameAsTypeUri + "> .\n"
				+ "}\n"
				;
				
		return query;
	}
	
	private String generateGetBadSameCardinalityErr() throws Exception {

		String query = 
				"select distinct ?same_as \n"
				+ SparqlToXLibUtil.generateSparqlFromOrUsing("", "FROM", this.conn, this.oInfo) + "\n"
				+ " where {\n"
				+ "     { \n"
				+ "	    	?same_as <" + this.targetPropUri    + "> ?object1 .\n"
				+ "	    	?same_as <" + this.targetPropUri    + "> ?object2 .\n"
				+ "         FILTER (?object1 != ?object2) ."
				+ "         ?same_as a <" + this.sameAsTypeUri + "> .\n"
				+ "     } UNION { \n"
				+ "	    	?same_as <" + this.duplicatePropUri    + "> ?object1 .\n"
				+ "	    	?same_as <" + this.duplicatePropUri    + "> ?object2 .\n"
				+ "         FILTER (?object1 != ?object2) ."
				+ "         ?same_as a <" + this.sameAsTypeUri + "> .\n"
				+ "     } UNION { \n"
				+ "         ?same_as a <" + this.sameAsTypeUri + "> .\n"
				+ "         FILTER NOT EXISTS { ?same_as <" + this.targetPropUri + "> ?object } .\n"
				+ "     } UNION { \n"
				+ "         ?same_as a <" + this.sameAsTypeUri + "> .\n"
				+ "         FILTER NOT EXISTS { ?same_as <" + this.duplicatePropUri + "> ?object } .\n"
				+ "     }\n"
				+ "}\n"
				;
				
		return query;
	}

}
