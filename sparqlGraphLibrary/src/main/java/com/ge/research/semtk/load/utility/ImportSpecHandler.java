/**
 ** Copyright 2016-8 General Electric Company
 **
 **
 ** Licensed under the Apache License, Version 2.0 (the "License");
 ** you may not use this file except in compliance with the License.
 ** You may obtain a copy of the License at
 ** 
 **     http://www.apache.org/licenses/LICENSE-2.0
 ** 
 ** Unless required by applicable law or agreed to in writing, software
 ** distributed under the License is distributed on an "AS IS" BASIS,
 ** WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 ** See the License for the specific language governing permissions and
 ** limitations under the License.
 */

package com.ge.research.semtk.load.utility;

import java.net.URI;
import java.security.MessageDigest;
import java.text.SimpleDateFormat;
import java.time.Duration;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.HashSet;
import java.util.UUID;

import javax.xml.bind.DatatypeConverter;

import org.json.simple.JSONObject;

import com.ge.research.semtk.belmont.AutoGeneratedQueryTypes;
import com.ge.research.semtk.belmont.BelmontUtil;
import com.ge.research.semtk.belmont.Node;
import com.ge.research.semtk.belmont.NodeGroup;
import com.ge.research.semtk.belmont.PropertyItem;
import com.ge.research.semtk.belmont.Returnable;
import com.ge.research.semtk.belmont.ValueConstraint;
import com.ge.research.semtk.load.DataValidator;
import com.ge.research.semtk.load.transform.Transform;
import com.ge.research.semtk.load.transform.TransformInfo;
import com.ge.research.semtk.ontologyTools.OntologyDatatype;
import com.ge.research.semtk.ontologyTools.OntologyInfo;
import com.ge.research.semtk.ontologyTools.OntologyName;
import com.ge.research.semtk.resultSet.Table;
import com.ge.research.semtk.resultSet.TableResultSet;
import com.ge.research.semtk.sparqlX.SparqlConnection;
import com.ge.research.semtk.sparqlX.SparqlEndpointInterface;
import com.ge.research.semtk.sparqlX.SparqlResultTypes;
import com.ge.research.semtk.sparqlX.SparqlToXUtils;
import com.ge.research.semtk.sparqlX.XSDSupportedType;
import com.ge.research.semtk.utility.LocalLogger;
import com.ge.research.semtk.utility.Utility;

/*
 * NOT a port of javascript ImportSpec.
 * Java-specific and highly optimized (ha) for ingestion 
 * Handles the importSpec portion of SparqlGraphJson
 * 
 * WARNING: This is shared by THREADS.  It must remain THREAD SAFE.
 */
public class ImportSpecHandler {

	ImportSpec importspec = null;

	JSONObject nodegroupJson = null;
	NodeGroup ng = null;
	SparqlConnection lookupConn = null;
	HashMap<String, JSONObject> lookupNodegroupsJson = new HashMap<String, JSONObject>(); // cache of pruned nodegroups
																							// ready for lookup
	HashMap<String, String> lookupNodegroupMD5 = new HashMap<String, String>(); // MD5 hash for standardized lookup
																				// nodegroup.
	HashMap<String, String> lookupMode = new HashMap<String, String>();
	HashMap<String, Long> lookupResultCount = new HashMap<String, Long>(); // number of URI's in the triple-store to
																			// choose from. zero or non-zero.

	HashMap<String, Integer> colNameToIndexHash = new HashMap<String, Integer>();
	HashMap<String, Transform> transformHash = new HashMap<String, Transform>();
	HashMap<String, String> textHash = new HashMap<String, String>();
	HashMap<String, String> colNameHash = new HashMap<String, String>();
	HashMap<String, Integer> colsUsed = new HashMap<String, Integer>(); // count of cols used. Only includes counts > 0

	ImportMapping importMappings[] = null;
	HashMap<String, ArrayList<ImportMapping>> lookupMappings = new HashMap<String, ArrayList<ImportMapping>>(); // for each node, the mappings that do URI lookup

	UriResolver uriResolver;
	OntologyInfo oInfo;

	UriCache uriCache = null;

	SparqlEndpointInterface nonThreadSafeEndpoint = null; // Endpoint for looking up URI's. It is not thread safe, so it
															// must be copied before being used.

	DataValidator dataValidator = null;

	HashMap<String, UriLookupPerfMonitor> lookupPerfMonitors = new HashMap<String, UriLookupPerfMonitor>();
	

	public ImportSpecHandler(JSONObject importSpecJson, JSONObject ngJson, SparqlConnection lookupConn,
			OntologyInfo oInfo) throws Exception {
		this.importspec = new ImportSpec(importSpecJson);

		// reset the nodegroup and store as json (for efficient duplication)
		this.ng = NodeGroup.getInstanceFromJson(ngJson);
		this.ng.validateAgainstModel(oInfo);
		this.ng.reset();
		this.nodegroupJson = ng.toJson();

		this.oInfo = oInfo;

		this.lookupConn = lookupConn;

		this.colHashesFromJson();
		this.transformsFromJson();
		this.textHashFromJson();
		this.nodesFromJson();
		String userUriPrefixValue = this.importspec.getBaseURI();

		this.uriResolver = new UriResolver(userUriPrefixValue, oInfo);

		this.uriCache = new UriCache();

		this.dataValidator = new DataValidator(this.importspec.getDataValidatorJson());
		this.errorCheckImportSpec();
	}

	public ImportSpec getImportSpec() {
		return this.importspec;
	}

	/**
	 * Override baseURI in a JSON object.
	 * 
	 * @param importSpecJson
	 * @param override
	 * @return
	 */
	public static JSONObject overrideBaseURI(JSONObject importSpecJson, String override) {
		ImportSpec tmp = new ImportSpec(importSpecJson);
		tmp.setBaseURI(override);
		return tmp.toJson();
	}

	public void setEndpoint(SparqlEndpointInterface endpoint) {
		this.nonThreadSafeEndpoint = endpoint;
	}

	/**
	 * Set the data source headers
	 * 
	 * @param headers
	 * @throws Exception
	 */
	public void setHeaders(ArrayList<String> headers) throws Exception {
		HashMap<String, Integer> oldNameToIndexHash = this.colNameToIndexHash;
		HashMap<String, Integer> newNameToIndexHash = new HashMap<String, Integer>();
		HashMap<Integer, Integer> translateHash = new HashMap<Integer, Integer>();

		// build hashes
		int counter = 0;
		for (String h : headers) {
			String name = h.toLowerCase();
			// build new colNameToIndexHash
			newNameToIndexHash.put(name, counter);
			// build a translation hash
			translateHash.put(oldNameToIndexHash.get(name), counter);
			counter += 1;
		}

		HashSet<MappingItem> done = new HashSet<MappingItem>();

		// change every mapping item's column index
		for (int i = 0; i < this.importMappings.length; i++) {
			for (MappingItem mItem : this.importMappings[i].getItemList()) {
				if (!done.contains(mItem)) {
					mItem.updateColumnIndex(translateHash, oldNameToIndexHash);
					done.add(mItem);
				}
			}
		}

		// repeat for URI lookup mappings
		for (String id : this.lookupMappings.keySet()) {
			for (ImportMapping map : this.lookupMappings.get(id)) {
				for (MappingItem mItem : map.getItemList()) {
					if (!done.contains(mItem)) {
						mItem.updateColumnIndex(translateHash, oldNameToIndexHash);
						done.add(mItem);
					}
				}
			}
		}

		// use the new name-to-index hash
		this.colNameToIndexHash = newNameToIndexHash;
	}

	/**
	 * Return may be an empty DataValidator, but not null
	 * 
	 * @return
	 */
	public DataValidator getDataValidator() {
		return this.dataValidator;
	}

	public String getUriPrefix() {
		return uriResolver.getUriPrefix();
	}

	/**
	 * Populate the transforms with the correct instances based on the importspec.
	 * 
	 * @throws Exception
	 */
	private void transformsFromJson() throws Exception {

		int tcount = this.importspec.getNumTransforms();

		for (int i = 0; i < tcount; ++i) {
			String instanceID = this.importspec.getTransformId(i);
			String transType = this.importspec.getTransformType(i);

			// go through all the entries besides "name", "transType", "transId" and
			// add them to the outgoing HashMap to be sent to the transform creation.
			int totalArgs = TransformInfo.getArgCount(transType);

			// get the args.
			HashMap<String, String> args = new HashMap<String, String>();
			if (totalArgs == 2) {
				args.put("arg1", this.importspec.getTransformArg1(i));
				args.put("arg2", this.importspec.getTransformArg2(i));
			}

			// get the transform instance.
			Transform currXform = TransformInfo.buildTransform(transType, instanceID, args);

			// add it to the hashMap.
			this.transformHash.put(instanceID, currXform);
		}
	}

	/**
	 * Populate the texts with the correct instances based on the importspec.
	 * 
	 * @throws Exception
	 */
	private void textHashFromJson() throws Exception {

		int tcount = this.importspec.getNumTexts();

		for (int i = 0; i < tcount; ++i) {
			String instanceID = this.importspec.getTextId(i);
			String textVal = this.importspec.getTextText(i);
			this.textHash.put(instanceID, textVal);
		}
	}

	/**
	 * Populate the texts with the correct instances based on the importspec.
	 * 
	 * @throws Exception
	 */
	private void colHashesFromJson() throws Exception {

		int colCount = this.importspec.getNumColumns();

		for (int i = 0; i < colCount; ++i) {

			String colId = this.importspec.getColId(i);
			String colName = this.importspec.getColName(i).toLowerCase().trim();
			this.colNameHash.put(colId, colName);

			if (colNameToIndexHash.containsKey(colName)) {
				throw new Exception("Duplicate column name in nodegroup import spec: " + colName);
			}
			this.colNameToIndexHash.put(colName, i); // initialize colIndexHash with columns in the order provided
		}
	}

	/**
	 * 
	 * @param nodesJsonArr
	 * @throws Exception
	 */
	private void nodesFromJson() throws Exception {
		NodeGroup tmpImportNg = NodeGroup.getInstanceFromJson(this.nodegroupJson);
		tmpImportNg.clearOrderBy();
		ArrayList<ImportMapping> mappingsList = new ArrayList<ImportMapping>();
		// clear cols used
		colsUsed = new HashMap<String, Integer>();
		ImportMapping mapping = null;
		int numNodes = this.importspec.getNumNodes();
		// loop through .nodes
		for (int n = 0; n < numNodes; n++) {

			// ---- URI ----
			String nodeSparqlID = this.importspec.getNodeSparqlID(n);
			int nodeIndex = tmpImportNg.getNodeIndexBySparqlID(nodeSparqlID);
			if (nodeIndex == -1) {
				throw new Exception("Error in ImportSpec JSON: can't find node in nodegroup: " + nodeSparqlID);
			}
			String mode = this.importspec.getNodeLookupMode(n);
			// lookup mode
			if (mode != null) {
				switch (mode) {
				case ImportSpec.LOOKUP_MODE_CREATE:
				case ImportSpec.LOOKUP_MODE_NO_CREATE:
				case ImportSpec.LOOKUP_MODE_ERR_IF_EXISTS:
					this.lookupMode.put(nodeSparqlID, mode);
					break;
				default:
					throw new Exception("Unknown lookup mode: " + mode);
				}
			}

			// build mapping if it isn't empty AND it isn't a URILookup
			if (this.importspec.getNodeNumMappings(n) > 0) {

				mapping = new ImportMapping();

				// get node index
				String type = this.importspec.getNodeType(n);
				mapping.setIsEnum(this.oInfo.classIsEnumeration(type));
				mapping.setNodeSparqlID(this.importspec.getNodeSparqlID(n));
				setupMappingItemList(n, mapping);

				// add non-lookup mappings to mapping list
				if (this.importspec.getNodeNumURILookups(n) == 0) {
					mappingsList.add(mapping);
				}

			}
			// handle URILookup, even if mapping was missing or blank
			if (this.importspec.getNodeNumURILookups(n) > 0) {
				this.setupUriLookup(this.importspec.getNodeSparqlID(n), this.importspec.getNodeURILookupList(n),
						mapping, tmpImportNg);
			}

			// ---- Properties ----
			int numProps = this.importspec.getNodeNumProperties(n);
			if (numProps > 0) {
				Node snode = tmpImportNg.getNode(nodeIndex);

				for (int p = 0; p < numProps; p++) {

					mapping = null;
					// build mapping if it isn't empty
					if (this.importspec.getNodePropNumMappings(n, p) > 0) {

						mapping = new ImportMapping();

						// populate the mapping
						mapping.setNodeSparqlID(this.importspec.getNodeSparqlID(n));
						mapping.setPropURI(this.importspec.getNodePropUriRel(n, p));
						setupMappingItemList(n, p, mapping);

						// add non-lookup mappings to mapping list
						if (this.importspec.getNodePropNumURILookups(n, p) == 0) {
							mappingsList.add(mapping);
						}

					}

					// handle URILookup, even if mapping was missing or blank
					if (this.importspec.getNodePropNumURILookups(n, p) > 0) {
						this.setupUriLookup(this.importspec.getNodePropUriRel(n, p),
								this.importspec.getNodePropURILookupList(n, p), mapping, tmpImportNg);
					}
				}
			}
		}

		// create some final efficient arrays
		this.importMappings = mappingsList.toArray(new ImportMapping[mappingsList.size()]);

		// lookups
		this.setupLookupNodegroups();
	}

	private void errorCheckImportSpec() throws Exception {

		// empty right now
	}

	/**
	 * Build lookupNodegroups by adding sample data & pruning.
	 * 
	 * @throws Exception
	 */
	private void setupLookupNodegroups() throws Exception {
		// make sure there is only one nodegroup per class being looked up
		HashMap<String,String> classToMD5Hash = new HashMap<String,String>();
		
		ArrayList<String> sample = new ArrayList<String>();
		sample.add("sample");

		NodeGroup importNg = NodeGroup.getInstanceFromJson(this.nodegroupJson);

		// for each node with lookupMapping(s)
		for (String importNodeId : this.lookupMappings.keySet()) {
			// initialize to "normal"
			NodeGroup lookupNg = NodeGroup.getInstanceFromJson(this.nodegroupJson);

			// add a sample value for each
			for (ImportMapping map : this.lookupMappings.get(importNodeId)) {
				Node node = lookupNg.getNodeBySparqlID(map.getNodeSparqlID());

				if (map.isNode()) {
					node.setValueConstraint(this.buildBestConstraint(node, sample));
				} else {
					PropertyItem propItem = node.getPropertyByURIRelation(map.getPropURI());
					if (propItem == null) {
						throw new Exception("Corrupt nodegroup: Can't find " + map.getPropURI() + " in node "
								+ node.getBindingOrSparqlID());
					}
					// make sure there's a sparql ID
					if (propItem.getSparqlID().equals("")) {
						String sparqlID = BelmontUtil.generateSparqlID(propItem.getKeyName(),
								importNg.getAllVariableNames());
						propItem.setSparqlID(sparqlID);
					}

					// apply value constraint so it isn't pruned
					propItem.setValueConstraint(this.buildBestConstraint(propItem, sample));
				}
			}

			// prune
			Node lookupNode = lookupNg.getNodeBySparqlID(importNodeId);
			lookupNode.setIsReturned(true);
			lookupNg.pruneAllUnused();
			lookupNg.removeUnusedBindings(); // for fuseki. Perhaps generic sparql gen solution would be better.

			this.lookupNodegroupsJson.put(importNodeId, lookupNg.toJson());
			this.lookupPerfMonitors.put(importNodeId, new UriLookupPerfMonitor(this.lookupMappings.get(importNodeId).size()));

			// standardize sparqlids, then generate sparql, then hash it
			// so we can tell if two lookup nodegroups are identical
			lookupNg.assignStandardSparqlIds();
			String sparql = lookupNg.generateSparqlSelect();
			MessageDigest messageDigest = MessageDigest.getInstance("MD5");
			messageDigest.update(sparql.getBytes());
			byte[] digiest = messageDigest.digest();
			String ngMD5 = DatatypeConverter.printHexBinary(digiest);
			this.lookupNodegroupMD5.put(importNodeId, ngMD5);

			// error check different columns looking up same type with non-equal nodegroups
			String mode = this.lookupMode.get(importNodeId);
			if (mode != null && mode.equals(ImportSpec.LOOKUP_MODE_CREATE)) {
				String classUri = lookupNode.getFullUriName();
				if (classToMD5Hash.containsKey(classUri)) {
					if (!classToMD5Hash.get(classUri).equals(ngMD5)) {
						throw new Exception(String.format("Class %s is 'create if missing' in multiple columns with URI lookup using different criteria.\nThis may result in duplicates.\nFix: split into multiple ingestion templates and steps.", lookupNode.getUri(true)));
					}
				} else {
					classToMD5Hash.put(classUri, ngMD5);
				}
			}
		}
	}

	/**
	 * Create a lookupNodegroup from it's json plus the lookup SparqlConnection
	 * 
	 * @param nodeIndex
	 * @return
	 * @throws Exception
	 */
	private NodeGroup getLookupNodegroup(String nodeID) throws Exception {
		NodeGroup lookupNodegroup = NodeGroup.getInstanceFromJson(this.lookupNodegroupsJson.get(nodeID));
		lookupNodegroup.setSparqlConnection(this.lookupConn);
		lookupNodegroup.noInflateNorValidate(this.oInfo);
		return lookupNodegroup;
	}

	/**
	 * Add a lookup ImportMapping to this.lookupMappings in the right place(s). For
	 * any node this is looking up.
	 * 
	 * @param uriLookupJsonArr
	 * @param mapping          - mapping of the node or property which owns this URI
	 *                         lookup, or null if none
	 * @param tmpNodegroup     - example nodegroup
	 * @throws Exception - lots of error checks for bad JSON
	 */
	private void setupUriLookup(String name, ArrayList<String> uriLookupList, ImportMapping mapping,
			NodeGroup tmpNodegroup) throws Exception {

		// error check missing or empty mapping
		if (mapping == null) {
			throw new Exception("Error in ImportSpec. Item is a URI lookup but has no mapping: " + name);
		} else if (mapping.getItemList().size() < 1) {
			throw new Exception("Error in ImportSpec. Item is a URI lookup but has empty mapping: " + name);
		}

		//
		if (uriLookupList.size() == 0) {
			throw new Exception("Error in ImportSpec: Empty URI lookup: " + name);

		} else {

			// loop through the sparql ID's of nodes this item is looking up
			for (int j = 0; j < uriLookupList.size(); j++) {
				String lookupSparqlID = uriLookupList.get(j);

				// add mapping to this.lookupMappings
				if (!this.lookupMappings.containsKey(lookupSparqlID)) {
					this.lookupMappings.put(lookupSparqlID, new ArrayList<ImportMapping>());
				}
				// add copies of the mapping to each lookupMapping
				this.lookupMappings.get(lookupSparqlID).add(ImportMapping.importSpecCopy(mapping));
			}
		}
	}

	/**
	 * Put mapping items from json into an ImportMapping and update colUsed
	 * 
	 * @param mappingJsonArr
	 * @param mapping
	 * @throws Exception
	 */
	private void setupMappingItemList(int nodeIndex, ImportMapping mapping) throws Exception {
		int mappingSize = this.importspec.getNodeNumMappings(nodeIndex);
		for (int i = 0; i < mappingSize; i++) {

			// mapping item
			MappingItem mItem = new MappingItem(this.importspec.getNodeMappingTextId(nodeIndex, i),
					this.importspec.getNodeMappingColId(nodeIndex, i),
					this.importspec.getNodeMappingTransformList(nodeIndex, i), this.colNameHash,
					this.colNameToIndexHash, this.textHash, this.transformHash);
			mapping.addItem(mItem);

			String colId = this.importspec.getNodeMappingColId(nodeIndex, i);
			if (colId != null) {
				// column item
				String colName = this.colNameHash.get(colId);
				// colsUsed
				if (this.colsUsed.containsKey(colName)) {
					this.colsUsed.put(colName, this.colsUsed.get(colName) + 1);
				} else {
					this.colsUsed.put(colName, 1);
				}
			}
		}
	}

	/**
	 * Put mapping items from json into an ImportMapping and update colUsed
	 * 
	 * @param mappingJsonArr
	 * @param mapping
	 * @throws Exception
	 */
	private void setupMappingItemList(int nodeIndex, int propIndex, ImportMapping mapping) throws Exception {
		int mappingSize = this.importspec.getNodePropNumMappings(nodeIndex, propIndex);
		for (int i = 0; i < mappingSize; i++) {

			// mapping item
			MappingItem mItem = new MappingItem(this.importspec.getNodePropMappingTextId(nodeIndex, propIndex, i),
					this.importspec.getNodePropMappingColId(nodeIndex, propIndex, i),
					this.importspec.getNodePropMappingTransformList(nodeIndex, propIndex, i), this.colNameHash,
					this.colNameToIndexHash, this.textHash, this.transformHash);
			mapping.addItem(mItem);

			String colId = this.importspec.getNodePropMappingColId(nodeIndex, propIndex, i);
			if (colId != null) {
				// column item
				String colName = this.colNameHash.get(colId);
				// colsUsed
				if (this.colsUsed.containsKey(colName)) {
					this.colsUsed.put(colName, this.colsUsed.get(colName) + 1);
				} else {
					this.colsUsed.put(colName, 1);
				}
			}
		}
	}

	/**
	 * Create a nodegroup to ingest a single record Always performs URILookup
	 * (checking UriCache first), possibly setting to NOT_FOUND
	 * 
	 * In order to accommodate threading and generation of unknown Uris, this
	 * function must always be called twice: Option 1: "pre-check"
	 * buildImportNodegroup(record, false) // do validation and URI lookup. Threaded
	 * if desired. // Caller join threads and make sure all validations passed, or
	 * quit. generateNotFoundURIs() // generate any legally not found URI's after
	 * validation threads are joined buildImportNodegroup(record, true) // quicker
	 * generation using cached URI's and no validation // This can be threaded //
	 * caller should do the insert on the nodegroup
	 * 
	 * Option 2: "single pass" buildImportNodegroup(record, true) // No validation
	 * of types. URI lookup with silent failure. Threaded if desired. // Even though
	 * not validating, this pass is needed to discover NOT_FOUND Uri's
	 * generateNotFoundURIs() // generate any legally not found URI's after threads
	 * are joined buildImportNodegroup(record, false) // validation and nodegroup
	 * generation using cached URI's // This can be threaded // caller should insert
	 * nodegroup. Incomplete load possible. // caller report any incomplete loads
	 * 
	 * @param record
	 * @param skipValidation
	 * @return
	 * @throws Exception
	 */
	public NodeGroup buildImportNodegroup(ArrayList<String> record, boolean skipValidation) throws Exception {

		// create a new nodegroup copy.
		NodeGroup retNodegroup = NodeGroup.getInstanceFromJson(this.nodegroupJson);
		retNodegroup.clearOrderBy();

		if (record == null) {
			throw new Exception("incoming record cannot be null for ImportSpecHandler.getValues");
		}
		if (this.colNameToIndexHash.isEmpty()) {
			throw new Exception("the header positions were never set for the importspechandler");
		}

		// fill in all URI's, possibly with NOT_FOUND if that's legal
		try {
			this.lookupAllUris(retNodegroup, record);
		} catch (Exception e) {
			// swallow URI lookup exception if we're skipping validation
			if (!skipValidation) {
				throw e;
			}
		}

		// do mappings
		for (int i = 0; i < this.importMappings.length; i++) {
			this.addMappingToNodegroup(retNodegroup, this.importMappings[i], record, skipValidation);
		}

		// do lookupMappings for any URI that was just generated - creating so fill it
		// in
		// also fill in EMPTY-LOOKUPs so they don't get pruned. This will throw an error
		// later: empty lookup column
		for (int i = 0; i < retNodegroup.getNodeCount(); i++) {
			Node n = retNodegroup.getNode(i);

			// Fixed a bug here by adding this.uriCache.isEmptyLookup() condition.
			// EMPTY-LOOKUPs should have any other mappings added so that error handling
			// works later
			// If all mappings are empty then the empty node might be prunable and the
			// ingestion succeeds without it.
			// See git commit 9/24/2021
			// See DataLoaderTest_IT.testMissingURILookups()
			if (this.uriCache.isGenerated(n.getInstanceValue()) || this.uriCache.isEmptyLookup(n.getInstanceValue())) {
				for (ImportMapping lookupMapping : this.lookupMappings.get(n.getSparqlID())) {
					this.addMappingToNodegroup(retNodegroup, lookupMapping, record, skipValidation);
				}
			}
		}

		// prune nodes that no longer belong (no uri and no properties)
		this.pruneImportNodegroup(retNodegroup);

		// set URI for nulls
		retNodegroup = this.setURIsForNullNodes(retNodegroup);
		return retNodegroup;
	}

	/**
	 * Prune an import nodegroup, checking for empty URI lookups
	 * 
	 * @param importNg
	 * @throws Exception
	 */
	private void pruneImportNodegroup(NodeGroup importNg) throws Exception {

		// remove all EMPTY_LOOKUP URIs from the nodegroup, remembering their sparqlIDs
		HashSet<String> emptyLookupSparqlIDs = new HashSet<String>();
		for (int i = 0; i < importNg.getNodeCount(); i++) {
			Node n = importNg.getNode(i);
			String instanceVal = n.getInstanceValue();
			if (instanceVal != null && instanceVal.equals(UriCache.EMPTY_LOOKUP)) {
				// remove the value so it might be pruned
				n.setInstanceValue(null);
				// remember the sparqlID
				emptyLookupSparqlIDs.add(n.getSparqlID());
			}
		}

		// prune the nodegroup
		importNg.pruneAllUnused(true);

		// make sure all the EMPTY_LOOKUP URIs are gone (pruned)
		for (String id : emptyLookupSparqlIDs) {
			Node n = importNg.getNodeBySparqlID(id);
			if (n != null) {
				throw new Exception("At least one URI lookup field was null: " + id);
			}
		}
	}

	/**
	 * After a possibly threaded pass where lookupURI labeled some URI's as
	 * NOT_FOUND Now go through and generate GUIDs for them.
	 * 
	 * @throws Exception
	 */
	public void generateNotFoundURIs() throws Exception {
		this.uriCache.generateNotFoundURIs(this.uriResolver);
	}

	/**
	 * Use record to add mapping value to an import nodegroup
	 * 
	 * @param importNodegroup
	 * @param mapping
	 * @param record
	 * @param skipValidation
	 * @throws Exception
	 */
	private void addMappingToNodegroup(NodeGroup importNodegroup, ImportMapping mapping, ArrayList<String> record,
			boolean skipValidation) throws Exception {
		String builtString = mapping.buildString(record);
		Node node = importNodegroup.getNodeBySparqlID(mapping.getNodeSparqlID());
		PropertyItem propItem = null;

		if (mapping.isProperty()) {
			// ---- property ----
			if (builtString.length() > 0) {
				propItem = node.getPropertyByURIRelation(mapping.getPropURI());
				builtString = ImportSpecHandler.validateDataType(builtString, propItem.getValueTypes(), skipValidation);

				// if datatype, check for restrictions
				// (SADL seems to only support restrictions on named datatypes,
				// so SemTK currently only supports restrictions on them)
				if (!skipValidation) {
					OntologyDatatype dt = this.oInfo.getDatatype(propItem.getRangeURI());
					if (dt != null) {
						dt.validateRestrictions(builtString);
					}
				}

				propItem.addInstanceValue(builtString);
			}

		} else {

			// ---- node ----

			// Mapping is invalid if URI has already been looked up. Return.
			if (node.getInstanceValue() != null)
				return;

			// if build string is null
			if (builtString.length() < 1) {
				node.setInstanceValue(null);
			}

			// use built string
			else {
				String uri = this.uriResolver.getInstanceUriWithPrefix(node.getFullUriName(), builtString);
				if (!SparqlToXUtils.isLegalURI(uri)) {
					throw new Exception("Attempting to insert ill-formed URI: " + uri);
				}
				node.setInstanceValue(uri);
			}
		}
	}

	/**
	 * lookup each URI for a nodegroup
	 * 
	 * @param importNg
	 * @param record
	 * @throws Exception
	 */
	private void lookupAllUris(NodeGroup importNg, ArrayList<String> record) throws Exception {
		// do URI lookups first
		for (String id : this.lookupMappings.keySet()) {
			Node n = importNg.getNodeBySparqlID(id);
			String uri = this.lookupUri(id, n.getUri(), record);
			n.setInstanceValue(uri);

			// save the fact that this uri was looked up and found
			if (this.uriCache.wasFound(uri)) {
				n.setInstanceLookedUp(true);
			}
		}
	}

	/**
	 * Look up a URI. Checking URICache first, and saving results to URICache. If
	 * URI is not found and MODE_CREATE, then it returns UriCache.NOT_FOUND and
	 * caller is responsible for generating not found guids.
	 * 
	 * @param ImportMappings
	 * @return uri or URICache.NOT_FOUND or URICache.EMPTY_LOOKUP
	 * @throws Exception - error, or not found and NO_CREATE, or found multiple
	 */
	private String lookupUri(String nodeID, String nodeUri, ArrayList<String> record) throws Exception {

		this.lookupPerfMonitors.get(nodeID).recordLookup();
		
		// get total possible number available, if it isn't known
		if (!this.lookupResultCount.containsKey(nodeID)) {
			this.lookupResultCount.put(nodeID, this.lookupCount(nodeID, 2));
		}

		// create a new nodegroup copy:
		ArrayList<String> mappedStrings = new ArrayList<String>();

		// Build the mapping results into mappedStrings
		for (ImportMapping mapping : this.lookupMappings.get(nodeID)) {
			String mappedStr = mapping.buildString(record);

			// check for empties
			if (mappedStr == null || mappedStr.isEmpty()) {
				return UriCache.EMPTY_LOOKUP;
			}

			mappedStrings.add(mappedStr);
		}

		this.expandMappedStrings(nodeID, mappedStrings);

		// return quickly if answer is already cached
		String cachedUri = this.uriCache.getUri(this.lookupNodegroupMD5.get(nodeID), mappedStrings);

		// if already cached
		if (cachedUri != null) {

			// if "createIfMissing" and has a mapping and is a generated (not looked up) URI
			if (this.lookupMode.containsKey(nodeID) && this.lookupMode.get(nodeID).equals(ImportSpec.LOOKUP_MODE_CREATE)
					&& this.getImportMapping(nodeID, ImportMapping.NO_PROPERTY) != null
					&& this.uriCache.isGenerated(cachedUri)) {

				// make sure that two different records aren't creating different values for
				// same URI
				ImportMapping map = this.getImportMapping(nodeID, ImportMapping.NO_PROPERTY);
				String newUri = map.buildString(record);

				if (!newUri.equals(cachedUri)) {
					if (newUri.equals(UriCache.NOT_FOUND)) {
						newUri = "<GUID>";
					}
					if (cachedUri.equals(UriCache.NOT_FOUND)) {
						cachedUri = "<GUID>";
					}
					throw new Exception(
							"Can't create a URI with two different values: " + cachedUri + " and " + newUri);
				}
			}

			// survived the check: return the cached value
			return cachedUri;

		} else {
			NodeGroup lookupNodegroup = null; // only build when needed (queries and errors)

			// Run the query
			// make this thread-safe
			Table tab = null;
			if (this.lookupResultCount.get(nodeID) == 0) {
				// don't run a query if we know it's going to fail.
				tab = new Table(new String[] { "empty_row" }, new String[] { "string" });

			} else {
				long startTime = System.nanoTime();
				lookupNodegroup = this.getLookupNodegroup(nodeID);
				SparqlEndpointInterface safeEndpoint = this.nonThreadSafeEndpoint.copy();
				String query = this.getLookupQuery(lookupNodegroup, nodeID, mappedStrings);

				TableResultSet res = (TableResultSet) safeEndpoint.executeQueryAndBuildResultSet(query,
						SparqlResultTypes.TABLE);
				res.throwExceptionIfUnsuccessful();
				tab = res.getTable();
				this.lookupPerfMonitors.get(nodeID).recordIndivQuery(System.nanoTime() - startTime);
			}

			// Check and return results
			if (tab.getNumRows() > 1) {
				// multiple found: error
				String lookup = lookupNodegroup.getReturnedSparqlIDs().toString();
				throw new Exception("URI lookup on " + lookup + " found multiple URI's matching: "
						+ String.join(",", mappedStrings));

			} else if (tab.getNumRows() == 0) {
				// zero found
				if (this.getLookupMode(nodeID).equals(ImportSpec.LOOKUP_MODE_NO_CREATE)) {
					// this is the only spot where we didn't run query but need lookupNodegroup for
					// error msg
					if (lookupNodegroup == null) {
						lookupNodegroup = this.getLookupNodegroup(nodeID);
					}
					String lookup = lookupNodegroup.getReturnedSparqlIDs().toString();
					throw new Exception("URI lookup on " + lookup + " failed on: " + String.join(",", mappedStrings));

				} else {
					// set URI to NOT_FOUND
					ImportMapping m = this.getImportMapping(nodeID, ImportMapping.NO_PROPERTY);
					this.uriCache.setUriNotFound(this.lookupNodegroupMD5.get(nodeID), mappedStrings,
							(m == null) ? null : m.buildString(record));
					return UriCache.NOT_FOUND;
				}

			} else {
				// 1 found: cache and return
				if (this.getLookupMode(nodeID).equals(ImportSpec.LOOKUP_MODE_ERR_IF_EXISTS)) {
					String lookup = lookupNodegroup.getReturnedSparqlIDs().toString();
					throw new Exception("URI lookup on 'error if exists' " + lookup + " already exists for: "
							+ String.join(",", mappedStrings));

				} else {
					// found 1. Normal success.
					String uri = tab.getCell(0, 0);
					this.uriCache.putUri(this.lookupNodegroupMD5.get(nodeID), mappedStrings, uri);
					//LocalLogger.logToStdErr("PUT INDIV   : " + String.join(",",mappedStrings));

					// if we found a URI in via lookup in triplestore, cache some more
					this.preFetchUriCache(lookupNodegroup, nodeID);

					return uri;
				}
			}
		}
	}
	
	

	private String getLookupQuery(NodeGroup lookupNodegroup, String nodeID, ArrayList<String> mappedStrings)
			throws Exception {

		// loop through lookupMappings and add constraints to the lookupNodegroup
		int i = 0;
		for (ImportMapping mapping : this.lookupMappings.get(nodeID)) {
			// short-hand for:
			// String builtStr = mapping.buildString(record);
			String mappedStr = mappedStrings.get(i++);

			Node node = lookupNodegroup.getNodeBySparqlID(mapping.getNodeSparqlID());

			if (mapping.isNode()) {

				node.setValueConstraint(this.buildBestConstraint(node, mappedStr));

			} else {
				PropertyItem prop = node.getPropertyByURIRelation(mapping.getPropURI());
				prop.setValueConstraint(this.buildBestConstraint(prop, mappedStr));
			}
		}

		return lookupNodegroup.generateSparql(AutoGeneratedQueryTypes.SELECT_DISTINCT, false, 0, null);
	}

	/**
	 * Expand mappedStrings if incomplete enumeration or short-hand generated Uri
	 * 
	 * @param nodeID
	 * @param nodeUri
	 * @param mappedStrings
	 * @throws Exception
	 */
	private void expandMappedStrings(String nodeID, ArrayList<String> mappedStrings) throws Exception {

		ArrayList<ImportMapping> mappings = this.lookupMappings.get(nodeID);
		for (int i = 0; i < mappings.size(); i++) {
			if (mappings.get(i).isNode()) {

				String builtString = mappedStrings.get(i);
				if (mappings.get(i).getIsEnum()) {
					String mappedNodeUri = this.ng.getNodeBySparqlID(mappings.get(0).getNodeSparqlID()).getUri();
					mappedStrings.set(i, this.oInfo.getMatchingEnumeration(mappedNodeUri, builtString));

				} else if (!builtString.contains("#")) {
					// add baseURI prefix if there is no prefix
					String nodeUri = this.ng.getNodeBySparqlID(nodeID).getUri();
					mappedStrings.set(i, this.uriResolver.getInstanceUriWithPrefix(nodeUri, builtString));
				}
			}
		}

	}

	/**
	 * Try prefetching some URI Lookups with an unconstrained lookup nodegroup
	 * 
	 * @param lookupNodegroup
	 * @param nodeID
	 */
	private void preFetchUriCache(NodeGroup lookupNodegroup, String nodeID) {

		// return if in progress on another thread, done, or there's been an error
		UriLookupPerfMonitor monitor = this.lookupPerfMonitors.get(nodeID);
		
		UriLookupPerfMonitor.READY ready = monitor.requestNextBatchQuery();
		if (ready == UriLookupPerfMonitor.READY.NO) 
			return;
		
		else if (ready == UriLookupPerfMonitor.READY.COUNT_NEEDED) {
			try {
				long countInTriplestore = this.lookupCount(nodeID, UriLookupPerfMonitor.PREFETCH_MAX_EXIST + 1);
				monitor.setUrisInTriplestore(countInTriplestore);
				if (monitor.requestNextBatchQuery() != UriLookupPerfMonitor.READY.YES) {
					return;
				}
			} catch (Exception e) {
				// can't count uris in triplestore:  stop everything forever
				monitor.setBatchQueryBlocked();
				return;
			}
		}
		
		// set offset and limit for this time
		int limit = monitor.getQueryLimit();
		int offset = monitor.getQueryOffset();

		// do the pre-fetch
		try {
			long startTime = System.nanoTime();

			ArrayList<ImportMapping> mappings = this.lookupMappings.get(nodeID);

			String colName[] = new String[mappings.size()];
			String uriColName = nodeID.substring(1);

			// remove all value constraints
			// IDEA: in crazy-large spaces, we could (randomly?) choose a subset to remove
			for (int i = 0; i < mappings.size(); i++) {
				ImportMapping mapping = mappings.get(i);
				Node node = lookupNodegroup.getNodeBySparqlID(mapping.getNodeSparqlID());

				if (mapping.isNode()) {
					colName[i] = node.getBindingOrSparqlID().substring(1);
					node.setValueConstraint(null);
					node.setIsReturned(true);
					lookupNodegroup.appendOrderBy(node.getBindingOrSparqlID());

				} else {
					PropertyItem prop = node.getPropertyByURIRelation(mapping.getPropURI());
					colName[i] = prop.getBindingOrSparqlID().substring(1);
					prop.setValueConstraint(null);
					prop.setIsReturned(true);
					lookupNodegroup.appendOrderBy(prop.getBindingOrSparqlID());

				}
			}

			lookupNodegroup.setLimit(limit);
			lookupNodegroup.setOffset(offset);

			// run the query
			String query = lookupNodegroup.generateSparqlSelect();
			SparqlEndpointInterface safeEndpoint = this.nonThreadSafeEndpoint.copy();

			TableResultSet res = (TableResultSet) safeEndpoint.executeQueryAndBuildResultSet(query,
					SparqlResultTypes.TABLE);
			res.throwExceptionIfUnsuccessful();
			Table tab = res.getTable();

			// If results came back
			if (tab.getNumRows() > 1) {
				// calculate duplicate mappedStrings.
				boolean skipRow[] = new boolean[tab.getNumRows()];
				String joinedMappedStrings[] = new String[tab.getNumRows()];
				for (int r = 0; r < tab.getNumRows(); r++) {
					skipRow[r] = false;
					joinedMappedStrings[r] = String.join("|||", tab.getRow(r).subList(1, tab.getNumColumns()));
				}
				// skip rows with duplicate mapped strings
				for (int r = 0; r < tab.getNumRows() - 1; r++) {
					if (joinedMappedStrings[r + 1].equals(joinedMappedStrings[r])) {
						skipRow[r] = true;
						skipRow[r + 1] = true;
					}
				}
				// also skip first and last since we don't have enough info
				skipRow[0] = true;
				skipRow[tab.getNumRows() - 1] = true;

				for (int r = 1; r < tab.getNumRows() - 1; r++) {

					if (skipRow[r])
						break;

					ArrayList<String> mappedStrings = new ArrayList<String>();
					for (int i = 0; i < mappings.size(); i++) {
						mappedStrings.add(tab.getCell(r, colName[i]));
					}
					String uri = tab.getCell(r, uriColName);
					// put into cache. No harm done if it is already there.
					// TODO : Not checking for same mapped strings but different uri.
					// Hopefully we've already eliminated that possibility? Should check anyway.
					this.uriCache.putUri(this.lookupNodegroupMD5.get(nodeID), mappedStrings, uri);
					//LocalLogger.logToStdErr("PUT BATCH   : " + String.join(",",mappedStrings));

				}

			}

			monitor.recordBatchQuery(System.nanoTime() - startTime, tab.getNumRows());
			
		} catch (Exception e) {
			// this.prefetchBlocked.get(nodeID) will remain true, aborting any further
			// attempts at pre-fetching.
			LocalLogger.logToStdErr("Exception during URI Lookup prefetch.  Aborting pre-fetching.");
			LocalLogger.printStackTrace(e);
		}
		return;
	}

	private ValueConstraint buildBestConstraint(Returnable item, String val) throws Exception {
		return new ValueConstraint(
				ValueConstraint.buildBestListConstraint(item, val, this.lookupConn.getDataInterface(0)));
	}

	private ValueConstraint buildBestConstraint(Returnable item, ArrayList<String> valList) throws Exception {
		return new ValueConstraint(
				ValueConstraint.buildBestListConstraint(item, valList, this.lookupConn.getDataInterface(0)));
	}

	// ---------------------------------------------

	private long lookupCount(String nodeID, int maxCount) throws Exception {

		// get the nodegroup
		NodeGroup lookupNodegroup = this.getLookupNodegroup(nodeID);

		// loop through lookupMappings and remove constraints
		for (ImportMapping mapping : this.lookupMappings.get(nodeID)) {
			Node node = lookupNodegroup.getNodeBySparqlID(mapping.getNodeSparqlID());

			if (mapping.isNode()) {
				node.setValueConstraint(null);

			} else {
				PropertyItem prop = node.getPropertyByURIRelation(mapping.getPropURI());
				prop.setValueConstraint(null);
			}
		}

		String query = lookupNodegroup.generateSparql(AutoGeneratedQueryTypes.COUNT, false, maxCount, null);

		// Run the query
		// make this thread-safe
		SparqlEndpointInterface safeEndpoint = this.nonThreadSafeEndpoint.copy();
		TableResultSet res = (TableResultSet) safeEndpoint.executeQueryAndBuildResultSet(query,
				SparqlResultTypes.TABLE);
		res.throwExceptionIfUnsuccessful();
		Table tab = res.getTable();

		return tab.getCellAsLong(0, 0);

	}

	/**
	 * Find an import mapping for the given node and property
	 * 
	 * @param nodeIndex
	 * @param propIndex - can be null for none
	 * @return ImportMapping or null
	 */
	private ImportMapping getImportMapping(String nodeSparqlId, String propURI) {
		for (int i = 0; i < this.importMappings.length; i++) {
			if (this.importMappings[i].getNodeSparqlID().equals(nodeSparqlId)
					&& this.importMappings[i].getPropURI().equals(propURI)) {
				return this.importMappings[i];
			}
		}
		return null;
	}

	/**
	 * Find lookupMode. If not set, then use the default.
	 * 
	 * @param nodeIndex
	 * @return - always a valid mode string
	 */
	private String getLookupMode(String nodeID) {
		String mode = this.lookupMode.get(nodeID);
		if (mode == null) {
			return ImportSpec.LOOKUP_MODE_NO_CREATE; // default mode
		} else {
			return mode;
		}
	}

	/**
	 * Return a pointer to every PropertyItem in ng that is used in the import spec
	 * mapping or URILookup
	 * 
	 * @param ng
	 * @return
	 */
	public ArrayList<PropertyItem> getUndeflatablePropItems(NodeGroup ng) {

		ArrayList<PropertyItem> ret = new ArrayList<PropertyItem>();

		if (this.importMappings != null) {
			for (int i = 0; i < this.importMappings.length; i++) {
				if (this.importMappings[i].isProperty()) {
					ImportMapping m = this.importMappings[i];
					PropertyItem pItem = ng.getNodeBySparqlID(m.getNodeSparqlID())
							.getPropertyByURIRelation(m.getPropURI());
					ret.add(pItem);
				}
			}
		}

		if (this.lookupMappings != null) {
			for (String id : this.lookupMappings.keySet()) {
				ArrayList<ImportMapping> mapList = this.lookupMappings.get(id);
				for (ImportMapping m : mapList) {
					if (m.isProperty()) {
						PropertyItem pItem = ng.getNodeBySparqlID(m.getNodeSparqlID())
								.getPropertyByURIRelation(m.getPropURI());
						if (!ret.contains(pItem)) {
							ret.add(pItem);
						}
					}
				}
			}
		}
		return ret;
	}

	/**
	 * Get all column names that were actually used in mappings.
	 * 
	 * @return
	 */
	public String[] getColNamesUsed() {
		String ret[] = new String[this.colsUsed.size()];
		int r = 0;

		int numCols = this.importspec.getNumColumns();
		for (int i = 0; i < numCols; i++) {
			// use col ids to get the properly-transformed name
			String colId = this.importspec.getColId(i);
			String colName = this.colNameHash.get(colId);

			if (this.colsUsed.containsKey(colName)) {
				ret[r++] = colName;
			}
		}
		return ret;
	}

	private NodeGroup setURIsForNullNodes(NodeGroup ng) throws Exception {
		for (Node n : ng.getNodeList()) {
			if (n.getInstanceValue() == null) {
				n.setInstanceValue(
						this.uriResolver.getInstanceUriWithPrefix(n.getFullUriName(), UUID.randomUUID().toString()));
			}
		}
		// return the patched results.
		return ng;
	}

	/**
	 * Does LOOKUP_MODE_CREATE or ERR_IF_EXISTS appear anywhere in the ImportSpec
	 * (i.e. is there any way to lookup a URI and create it if it doesn't exist)
	 * 
	 * @return
	 */
	public boolean containsLookupWithCreate() {
		for (String id : this.lookupMode.keySet()) {
			if (this.getLookupMode(id).equals(ImportSpec.LOOKUP_MODE_CREATE)
					|| this.getLookupMode(id).equals(ImportSpec.LOOKUP_MODE_ERR_IF_EXISTS)) {
				return true;
			}
		}
		return false;
	}

	public static String validateDataType(String input, HashSet<XSDSupportedType> expectedTypes) throws Exception {
		return validateDataType(input, expectedTypes, false);
	}

	public static String validateDataType(String input, HashSet<XSDSupportedType> expectedTypes, Boolean skipValidation)
			throws Exception {
		Exception eSave = null;

		for (XSDSupportedType expectedType : expectedTypes) {
			try {
				return validateDataType(input, expectedType, skipValidation);
			} catch (Exception e) {
				eSave = e;
			}
		}
		// if none of the types worked, throw the last exception
		throw eSave;
	}

	/**
	 * Validates and in some cases modifies/reformats an input based on type
	 * 
	 * @param input
	 * @param expectedType   - last part of the type, e.g. "float"
	 * @param skipValidation - if True, perform modifications but no validations
	 * @return - valid value
	 * @throws Exception - if invalid
	 */
	@SuppressWarnings("deprecation")
	public static String validateDataType(String input, XSDSupportedType expectedType, Boolean skipValidation)
			throws Exception {

		// from the XSD data types:
		// string | boolean | decimal | int | integer | negativeInteger |
		// nonNegativeInteger |
		// positiveInteger | nonPositiveInteger | long | float | double | duration |
		// dateTime | time | date | unsignedByte | unsignedInt | anySimpleType |
		// gYearMonth | gYear | gMonthDay;

		// added for the runtimeConstraint:
		// NODE_URI

		/**
		 * Please keep the wiki up to date
		 * https://github.com/ge-semtk/semtk/wiki/Ingestion-type-handling
		 */

		/**
		 * Somewhere along this journey, this functionality is almost duplicated inside
		 * XSDSupportedType
		 */

		// perform validations that change the input
		switch (expectedType) {
		case STRING:
			return input;
		case DATETIME:
			try {
				return Utility.getSPARQLDateTimeString(input);
			} catch (Exception e) {
				throw new Exception("attempt to use value \"" + input + "\" as type \"" + expectedType
						+ "\" failed. assumed cause:" + e.getMessage());
			}
		case DATE:
			try {
				return Utility.getSPARQLDateString(input);
			} catch (Exception e) {
				throw new Exception("attempt to use value \"" + input + "\" as type \"" + expectedType
						+ "\" failed. assumed cause:" + e.getMessage());
			}
		}

		// efficiency circuit-breaker
		if (skipValidation) {
			return input;
		}

		// perform plain old validations
		switch (expectedType) {
		case NODE_URI:
		case ANYURI:
			try {
				// check that this looks like a URI
				new URI(input);
			} catch (Exception e) {
				throw new Exception("attempt to use value \"" + input + "\" as type \"" + expectedType
						+ "\" failed. assumed cause: " + e.getMessage());
			}
			break;
		case BOOLEAN:
			String cmp = input.toLowerCase().trim();
			switch (cmp) {
			case "true":
			case "false":
				break;
			default:
				throw new Exception("attempt to use value \"" + input + "\" as type \"" + expectedType
						+ "\" failed. Use 'true' or 'false'");
			}
			break;
		case DECIMAL:
			try {
				Double.parseDouble(input);
			} catch (Exception e) {
				throw new Exception("attempt to use value \"" + input + "\" as type \"" + expectedType
						+ "\" failed. assumed cause:" + e.getMessage());
			}
			break;
		case INT:
		case INTEGER:
			try {
				Integer.parseInt(input);
			} catch (Exception e) {
				try {
					double d = Double.parseDouble(input);
					if (Math.ceil(d) != d) {
						throw new Exception("Float is not equivalent to any integer");
					}
				} catch (Exception ee) {
					throw new Exception("attempt to use value \"" + input + "\" as type \"" + expectedType
							+ "\" failed. assumed cause:" + e.getMessage());
				}
			}
			break;

		case LONG:
			try {
				Long.parseLong(input);
			} catch (Exception e) {
				try {
					double d = Double.parseDouble(input);
					if (Math.ceil(d) != d) {
						throw new Exception("Float is not equivalent to any long integer");
					}
				} catch (Exception ee) {
					throw new Exception("attempt to use value \"" + input + "\" as type \"" + expectedType
							+ "\" failed. assumed cause:" + e.getMessage());
				}
			}
			break;
		case FLOAT:
			try {
				Float.parseFloat(input);
			} catch (Exception e) {
				throw new Exception("attempt to use value \"" + input + "\" as type \"" + expectedType
						+ "\" failed. assumed cause:" + e.getMessage());
			}
			break;
		case DOUBLE:
			try {
				Double.parseDouble(input);
			} catch (Exception e) {
				throw new Exception("attempt to use value \"" + input + "\" as type \"" + expectedType
						+ "\" failed. assumed cause:" + e.getMessage());
			}
			break;
		case TIME:
			try {
				(new SimpleDateFormat("HH:mm:ss")).parse(input);
			} catch (Exception e) {
				throw new Exception("attempt to use value \"" + input + "\" as type \"" + expectedType
						+ "\" failed. assumed cause:" + e.getMessage());
			}
			break;
		case NEGATIVEINTEGER:
			try {
				int test = 0;
				try {
					test = Integer.parseInt(input);
				} catch (Exception e) {
					double d = Double.parseDouble(input);
					if (Math.ceil(d) != d) {
						throw new Exception("Float is not equivalent to any  integer");
					} else {
						test = (int) d;
					}
				}
				if (test >= 0) {
					throw new Exception("value in model is negative integer. non-negative integer given as input");
				}
			} catch (Exception e) {
				throw new Exception("attempt to use value \"" + input + "\" as type \"" + expectedType
						+ "\" failed. assumed cause:" + e.getMessage());
			}
			break;
		case NONNEGATIVEINTEGER:
			try {
				int test = 0;
				try {
					test = Integer.parseInt(input);
				} catch (Exception e) {
					double d = Double.parseDouble(input);
					if (Math.ceil(d) != d) {
						throw new Exception("Float is not equivalent to any  integer");
					} else {
						test = (int) d;
					}
				}
				if (test < 0) {
					throw new Exception("value in model is non-negative integer. negative integer given as input");
				}
			} catch (Exception e) {
				throw new Exception("attempt to use value \"" + input + "\" as type \"" + expectedType
						+ "\" failed. assumed cause:" + e.getMessage());
			}
			break;
		case POSITIVEINTEGER:
			try {
				int test = 0;
				try {
					test = Integer.parseInt(input);
				} catch (Exception e) {
					double d = Double.parseDouble(input);
					if (Math.ceil(d) != d) {
						throw new Exception("Float is not equivalent to any  integer");
					} else {
						test = (int) d;
					}
				}
				if (test <= 0) {
					throw new Exception("value in model is positive integer. negative integer given as input");
				}
			} catch (Exception e) {
				throw new Exception("attempt to use value \"" + input + "\" as type \"" + expectedType
						+ "\" failed. assumed cause:" + e.getMessage());
			}
			break;
		case NONPOSISITIVEINTEGER:
			try {
				int test = 0;
				try {
					test = Integer.parseInt(input);
				} catch (Exception e) {
					double d = Double.parseDouble(input);
					if (Math.ceil(d) != d) {
						throw new Exception("Float is not equivalent to any  integer");
					} else {
						test = (int) d;
					}
				}
				if (test > 0) {
					throw new Exception("value in model is non-positive integer. positive integer given as input");
				}
			} catch (Exception e) {
				throw new Exception("attempt to use value \"" + input + "\" as type \"" + expectedType
						+ "\" failed. assumed cause:" + e.getMessage());
			}
			break;

		case DURATION:
			// not sure how to check this one. this might not match the expectation from
			// SADL
			try {
				Duration.parse(input);
			} catch (Exception e) {
				throw new Exception("attempt to use value \"" + input + "\" as type \"" + expectedType
						+ "\" failed. assumed cause:" + e.getMessage());
			}
			break;
		case UNSIGNEDBYTE:
			try {
				Byte.parseByte(input);
			} catch (Exception e) {
				throw new Exception("attempt to use value \"" + input + "\" as type \"" + expectedType
						+ "\" failed. assumed cause:" + e.getMessage());
			}
			break;
		case UNSIGNEDINT:
			try {
				Integer.parseUnsignedInt(input);
			} catch (Exception e) {
				throw new Exception("attempt to use value \"" + input + "\" as type \"" + expectedType
						+ "\" failed. assumed cause:" + e.getMessage());
			}
			break;
		case ANYSIMPLETYPE:
			// do nothing.
			break;
		case GYEARMONTH:
			try {
				String[] all = input.split("-");
				// check them all
				if (all.length != 2) {
					throw new Exception("year-month did not have two parts.");
				}
				if (all[0].length() != 4 && all[1].length() != 2) {
					throw new Exception("year-month format was wrong. " + input + " given was not YYYY-MM");
				}
			} catch (Exception e) {
				throw new Exception("attempt to use value \"" + input + "\" as type \"" + expectedType
						+ "\" failed. assumed cause:" + e.getMessage());
			}
			break;
		case GMONTHDAY:
			try {
				String[] all = input.split("-");
				// check them all
				if (all.length != 2) {
					throw new Exception("month-day did not have two parts.");
				}
				if (all[0].length() != 2 && all[1].length() != 2) {
					throw new Exception("month-day format was wrong. " + input + " given was not MM-dd");
				}
			} catch (Exception e) {
				throw new Exception("attempt to use value \"" + input + "\" as type \"" + expectedType
						+ "\" failed. assumed cause:" + e.getMessage());
			}
			break;

		default:
			// unknown types slip through un-validated.
		}

		return input;
	}

	/**
	 * Return only column names, in order, with capitalization
	 * 
	 * @return comma-separated string
	 */
	public String getSampleCSV() {
		StringBuilder ret = new StringBuilder();

		for (int i = 0; i < this.importspec.getNumColumns(); i++) {
			ret.append((i == 0 ? "" : ",") + this.importspec.getColName(i));
		}
		ret.append('\n');
		return ret.toString();
	}

	/**
	 * Historical version: - loses order - loses capitalization - tries to add types
	 * 
	 * @return
	 */
	public String getSampleIngestionCSV() {

		HashMap<String, String> sampleHash = addSampleIngestionValues(null);

		// return "" if there's apparently no import spec
		if (sampleHash.isEmpty()) {
			return "";
		}

		StringBuilder ret = new StringBuilder();
		String colNames[] = this.getColNamesUsed();
		ret.append(String.join(",", colNames));
		ret.append("\n");

		String delim = "";
		for (String colName : colNames) {
			ret.append(delim + sampleHash.get(colName));
			delim = ",";
		}
		ret.append("\n");

		return ret.toString();

	}

	/**
	 * Add sample values to a hash <col_name, sample_value> Conflicts and
	 * too-complicated columns will be "value"
	 * 
	 * @param hash - can be null
	 * @return
	 */
	public HashMap<String, String> addSampleIngestionValues(HashMap<String, String> hash) {
		if (hash == null) {
			hash = new HashMap<String, String>();
		}

		// get columns and any discernable sample values
		String colNames[] = this.getColNamesUsed();
		HashMap<Integer, String> sampleHash = this.getColumnSampleValues();

		// build a hash of sample values
		for (String colName : colNames) {

			// get sample, setting to "value" if unknown/too-complicated
			String sample = sampleHash.get(this.colNameToIndexHash.get(colName));
			if (sample == null || sample.isEmpty()) {
				sample = "value";
			}

			// default all conflicts to "value"
			if (hash.containsKey(colName)) {
				if (!hash.get(colName).equals(sample)) {
					hash.put(colName, "value");
				}
			} else {
				hash.put(colName, sample);
			}
		}

		return hash;
	}

	public static String getSampleIngestionCSV(ArrayList<ImportSpecHandler> specList) {
		// get samples
		HashMap<String, String> sampleHash = null;
		for (ImportSpecHandler spec : specList) {
			sampleHash = spec.addSampleIngestionValues(sampleHash);
		}

		// return "" if there's apparently no import spec
		if (sampleHash.isEmpty()) {
			return "";
		}

		// add column names
		StringBuilder ret = new StringBuilder();
		String delim = "";
		for (String colName : sampleHash.keySet()) {
			ret.append(delim + colName);
			delim = ",";
		}
		ret.append("\n");

		// add values
		delim = "";
		for (String colName : sampleHash.keySet()) {
			ret.append(delim + sampleHash.get(colName));
			delim = ",";
		}
		ret.append("\n");

		return ret.toString();
	}

	/**
	 * Build a hashmap of <int_mapping_index, type_string> columns where we can
	 * figure out the type EMPTY for complicated columns
	 * 
	 * @return
	 */
	private HashMap<Integer, String> getColumnSampleValues() {
		HashMap<Integer, String> ret = new HashMap<Integer, String>();

		for (ImportMapping mapping : this.importMappings) {
			ArrayList<MappingItem> items = mapping.getItemList();

			// if it is a single column mapping with no transforms, we can guess type
			if (items.size() == 1 && items.get(0).isColumnMapping() && items.get(0).getTransformList().length == 0) {
				XSDSupportedType ngItemType = XSDSupportedType.chooseOne(this.getNodegroupItemTypes(mapping));

				Integer colIndex = items.get(0).getColumnIndex();
				String sample = ngItemType.getSampleValue();

				if (ngItemType.isURI() && mapping.getIsEnum()) {
					try {
						// if it's an enum, try to get the local fragment of the first legal value
						String uriName = this.ng.getNodeBySparqlID(mapping.getNodeSparqlID()).getFullUriName();
						String enumVal = this.oInfo.getEnumerationStrings(uriName).get(0);
						sample = new OntologyName(enumVal).getLocalName();
					} catch (Exception e) {
						sample = "enum";
					}
				}

				// conflicts change to strings
				if (ret.containsKey(colIndex) && !ret.get(colIndex).equals(sample)) {
					ret.put(colIndex, XSDSupportedType.STRING.getSampleValue());
				} else {
					ret.put(colIndex, sample);
				}
			}

		}
		return ret;
	}

	private HashSet<XSDSupportedType> getNodegroupItemTypes(ImportMapping map) {

		if (map.isNode()) {
			HashSet<XSDSupportedType> ret = new HashSet<XSDSupportedType>();
			ret.add(XSDSupportedType.NODE_URI);
			return ret;

		} else {
			return this.ng.getNodeBySparqlID(map.getNodeSparqlID()).getPropertyByURIRelation(map.getPropURI())
					.getValueTypes();
		}

	}
}
