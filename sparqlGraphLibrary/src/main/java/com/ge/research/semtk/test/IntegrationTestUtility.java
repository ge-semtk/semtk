/**
 ** Copyright 2016-2020 General Electric Company
 **
 **
 ** Licensed under the Apache License, Version 2.0 (the "License");
 ** you may not use this file except in compliance with the License.
 ** You may obtain a copy of the License at
 ** 
 **     http://www.apache.org/licenses/LICENSE-2.0
 ** 
 ** Unless required by applicable law or agreed to in writing, software
 ** distributed under the License is distributed on an "AS IS" BASIS,
 ** WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 ** See the License for the specific language governing permissions and
 ** limitations under the License.
 */

package com.ge.research.semtk.test;

import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertTrue;
import static org.junit.Assert.fail;
import static org.junit.Assume.assumeTrue;

import java.io.File;
import java.io.IOException;
import java.io.InputStream;
import java.util.Arrays;
import java.util.List;
import java.util.Properties;
import java.util.UUID;

import com.ge.research.semtk.api.nodeGroupExecution.NodeGroupExecutor;
import com.ge.research.semtk.api.nodeGroupExecution.client.NodeGroupExecutionClient;
import com.ge.research.semtk.api.nodeGroupExecution.client.NodeGroupExecutionClientConfig;
import com.ge.research.semtk.auth.AuthorizationProperties;
import com.ge.research.semtk.auth.ThreadAuthenticator;
import com.ge.research.semtk.belmont.AutoGeneratedQueryTypes;
import com.ge.research.semtk.belmont.NodeGroup;
import com.ge.research.semtk.edc.client.OntologyInfoClient;
import com.ge.research.semtk.edc.client.OntologyInfoClientConfig;
import com.ge.research.semtk.edc.client.ResultsClient;
import com.ge.research.semtk.edc.client.ResultsClientConfig;
import com.ge.research.semtk.edc.client.StatusClient;
import com.ge.research.semtk.edc.client.StatusClientConfig;
import com.ge.research.semtk.fdc.FdcClient;
import com.ge.research.semtk.fdc.FdcClientConfig;
import com.ge.research.semtk.load.client.IngestorClientConfig;
import com.ge.research.semtk.load.client.IngestorRestClient;
import com.ge.research.semtk.load.utility.SparqlGraphJson;
import com.ge.research.semtk.logging.easyLogger.LoggerClientConfig;
import com.ge.research.semtk.logging.easyLogger.LoggerRestClient;
import com.ge.research.semtk.nodeGroupStore.client.NodeGroupStoreConfig;
import com.ge.research.semtk.nodeGroupStore.client.NodeGroupStoreRestClient;
import com.ge.research.semtk.properties.EndpointProperties;
import com.ge.research.semtk.querygen.timeseries.TimeSeriesConstraint;
import com.ge.research.semtk.resultSet.Table;
import com.ge.research.semtk.sparqlX.SparqlEndpointInterface;
import com.ge.research.semtk.resultSet.TableResultSet;
import com.ge.research.semtk.sparqlX.client.SparqlQueryAuthClientConfig;
import com.ge.research.semtk.sparqlX.client.SparqlQueryClient;
import com.ge.research.semtk.sparqlX.client.SparqlQueryClientConfig;
import com.ge.research.semtk.sparqlX.dispatch.FdcServiceManager;
import com.ge.research.semtk.sparqlX.dispatch.client.DispatchClientConfig;
import com.ge.research.semtk.sparqlX.dispatch.client.DispatchRestClient;
import com.ge.research.semtk.utility.LocalLogger;
import com.ge.research.semtk.utility.Utility;

/**
 * Utility class for configuring integration tests.
 * 
 * NOTE: This class cannot be put in under src/test/java because it must remain accessible to other projects.
 */
public class IntegrationTestUtility{
	
	static Properties properties = null;
	
	public static Properties getProperties() throws IOException {
		loadProperties();
		return properties;
	}
	private static void loadProperties() throws IOException {
		if (properties == null) {
			properties = new Properties();
			InputStream is = IntegrationTestUtility.class.getResourceAsStream("/integrationtest.properties");
			properties.load(is);
		} 
	}
	public static String get(String key) throws Exception{ 
		loadProperties();
		if (!Utility.ENV_TEST) {
			throw new Exception(Utility.ENV_TEST_EXCEPTION_STRING);
		}
		if (key.startsWith("integrationtest")) {
			return Utility.getProperty(properties, key);
		} else {
			return Utility.getProperty(properties, "integrationtest." + key);
		}
	}
		
	public static int getInt(String key) throws Exception {
		return Integer.valueOf(get(key)).intValue();
	}
	
	// sparql endpoint
	public static String getSparqlServerOnly() throws Exception {
		String stripProtocol = get("sparqlendpoint.server").split("://")[1];
		String stripPort = stripProtocol.split(":")[0];
		return stripPort;
				
	}
	public static int getSparqlServerPort() throws Exception {
		String [] splitByColon = get("sparqlendpoint.server").split(":");
		String portMaybeEndpoint = splitByColon[2];
		return Integer.valueOf(portMaybeEndpoint.split("/")[0]);
	}
	
	/**
	 * Get JobEndpointProperties without domain or dataset
	 * @return
	 * @throws Exception
	 */
	public static EndpointProperties getEndpointProperties() throws Exception {
		EndpointProperties ret = new EndpointProperties();
		
		ret.setEndpointType(get("sparqlendpoint.type"));
		ret.setEndpointServerUrl(get("sparqlendpoint.server"));
		ret.setEndpointUsername(get("sparqlendpoint.username"));
		ret.setEndpointPassword(get("sparqlendpoint.password"));
		
		return ret;
	}
	
	public static AuthorizationProperties getAuthProperties() throws Exception {
		AuthorizationProperties ret = new AuthorizationProperties();
		ret.setUsernameKey(get("auth.usernameKey"));
		ret.setSettingsFilePath(get("auth.settingsFilePath"));
		try {
			ret.setRefreshFreqSeconds(Integer.parseInt(get("auth.refreshFreqSeconds")));
		} catch (Exception e) {
			// ok. optional property
		}
		return ret;
	}
	
	/**
	 * Get a ResultsClient using the integration test properties.
	 */
	public static ResultsClient getResultsClient() throws Exception{
		return new ResultsClient(getResultsClientConfig());
	}
	
	public static ResultsClientConfig getResultsClientConfig() throws Exception{
		return new ResultsClientConfig(get("protocol"), get("resultsservice.server"), getInt("resultsservice.port"));
	}
	
	/**
	 * Get a StatusClient using the integration test properties.
	 */
	public static StatusClient getStatusClient(String jobId) throws Exception{
		return new StatusClient(new StatusClientConfig(get("protocol"), get("statusservice.server"), getInt("statusservice.port"), jobId));
	}	
	
	public static SparqlEndpointInterface getServicesSei() throws Exception {
		return SparqlEndpointInterface.getInstance(
				get("sparqlendpoint.type"), 
				get("sparqlendpoint.server"),
				get("services.graph"), 
				get("sparqlendpoint.username"), 
				get("sparqlendpoint.password"));
	}
	
	/**
	 * Get a SparqlQueryClient using the integration test properties.
	 */
	public static SparqlQueryClient getSparqlQueryClient(String serviceEndpoint, String sparqlServer, String dataset) throws Exception{
		return new SparqlQueryClient(new SparqlQueryClientConfig(get("protocol"), get("sparqlqueryservice.server"), getInt("sparqlqueryservice.port"), serviceEndpoint, sparqlServer, get("sparqlendpoint.type"), dataset));
	}
	
	/**
	 * Get a SparqlQueryClient using the integration test properties.
	 */
	public static SparqlQueryClient getSparqlQueryAuthClient(String serviceEndpoint, String sparqlServer, String dataset) throws Exception{
		return new SparqlQueryClient(new SparqlQueryAuthClientConfig(get("protocol"), get("sparqlqueryservice.server"), getInt("sparqlqueryservice.port"), serviceEndpoint, sparqlServer, get("sparqlendpoint.type"), dataset, get("sparqlendpoint.username"), get("sparqlendpoint.password")));
	}
	
	public static SparqlQueryClient getSparqlQueryAuthClient() throws Exception{
		return new SparqlQueryClient(new SparqlQueryAuthClientConfig(get("protocol"), get("sparqlqueryservice.server"), getInt("sparqlqueryservice.port"), "/sparqlQueryService/query", get("sparqlendpoint.server"), get("sparqlendpoint.type"), TestGraph.getDataset(), get("sparqlendpoint.username"), get("sparqlendpoint.password")));
	}

	public static OntologyInfoClient getOntologyInfoClient() throws Exception{
		return new OntologyInfoClient(new OntologyInfoClientConfig(get("protocol"), get("ontologyinfoservice.server"), getInt("ontologyinfoservice.port")));
	}
	
	/**
	 * Get a LoggerRestClient using the integration test properties.
	 */
	public static LoggerRestClient getLoggerRestClient(String applicationName) throws Exception{
		return new LoggerRestClient(new LoggerClientConfig(applicationName, get("protocol"), get("loggingservice.server"), getInt("loggingservice.port"), get("loggingservice.endpoint")));
	}
	
	/**
	 * Get a NodeGroupStoreRestClient using the integration test properties.
	 */
	public static NodeGroupStoreRestClient getNodeGroupStoreRestClient() throws Exception{
		return new NodeGroupStoreRestClient(new NodeGroupStoreConfig(get("protocol"), get("nodegroupstoreservice.server"),  getInt("nodegroupstoreservice.port")));
	}
	
	public static String getNodeGroupStoreFullURL() throws Exception {
		return get("protocol") + "://" + get("nodegroupstoreservice.server") + ":" + get("nodegroupstoreservice.port");
	}
	/**
	 * Get a NodeGroupStoreRestClient using the integration test properties.
	 */
	public static NodeGroupExecutionClient getNodeGroupExecutionRestClient() throws Exception{
		return new NodeGroupExecutionClient(new NodeGroupExecutionClientConfig(get("protocol"), get("nodegroupexecution.server"), getInt("nodegroupexecution.port"), get("sparqlendpoint.username"), get("sparqlendpoint.password")));
	}
	
	/**
	 * Get a NodeGroupExecutor using the integration test properties.
	 */
	public static NodeGroupExecutor getNodegroupExecutor() throws Exception{
		NodeGroupStoreRestClient ngsrc = getNodeGroupStoreRestClient();
		DispatchRestClient drc = new DispatchRestClient(new DispatchClientConfig(get("protocol"), get("dispatchservice.server"), getInt("dispatchservice.port")));
		StatusClient stc = new StatusClient(new StatusClientConfig(get("protocol"), get("statusservice.server"), getInt("statusservice.port"), "totally fake"));
		ResultsClient rc  = new ResultsClient(new ResultsClientConfig(get("protocol"), get("resultsservice.server"), getInt("resultsservice.port")));
		IngestorRestClient ic = new IngestorRestClient(new IngestorClientConfig(get("protocol"), get("ingestionservice.server"), getInt("ingestionservice.port")));		
		SparqlEndpointInterface sei = getServicesSei();
		return new NodeGroupExecutor(ngsrc, drc, rc, sei, ic);
	}
	
	public static File getSampleFile(Object caller) throws Exception {
		return Utility.getResourceAsFile(caller, "/annotationBattery.owl");
	}
	
	public static String getSampleJsonBlob(Object caller) throws Exception {
		return Utility.getResourceAsString(caller, "/annotationBatteryOInfo.json");
	}
	
	public static Table getSampleTable() throws Exception {
		Table table = new Table(new String [] {"col1", "col2"}, new String [] {"string", "int"});
		table.addRow(new String [] {"value1", "2"});
		return table;
	}

	public static void authenticateJunit() {
		ThreadAuthenticator.authenticateThisThread("junit");
	}
	
	public static String generateUser(String testName, String suffix) {
		return "junit_" + testName + "_" + suffix;
	}
	
	public static String generateJobId(String testName) {
		return "junit_" + UUID.randomUUID().toString();
	}
	
	public static void cleanupNodegroupStore(String creator) throws Exception {
		cleanupNodegroupStore(getNodeGroupStoreRestClient(), creator);
	}

	public static void cleanupNodegroupStore(NodeGroupStoreRestClient nodeGroupStoreClient, String creator) throws Exception {
		// Clean up old nodegroups.   Shouldn't happen but it seems to.
		// So as not to interfere with others' testing, don't delete if creation date is today
		TableResultSet tabRes = nodeGroupStoreClient.executeGetNodeGroupMetadata();
		tabRes.throwExceptionIfUnsuccessful();
		Table storeTab = tabRes.getTable();
		String today = Utility.getSPARQLCurrentDateString();
		for (int i=0; i < storeTab.getNumRows(); i++) {
			if (storeTab.getCell(i,  "creator").equals(creator) && 
					! storeTab.getCell(i, "creationDate").equals(today)) {
				String id = storeTab.getCell(i, "ID");
				nodeGroupStoreClient.deleteStoredNodeGroup(id);
			}
		}
	}
	
	public static void compareResults(String actual, Object caller, String expectedResourceName) throws Exception {
		String expected = null;
		
		try {
			expected = Utility.getResourceAsString(caller, expectedResourceName);
		} catch (Exception e) {
			throw new Exception ("Error retrieving file: " + expectedResourceName, e);
		}
		
		String actualLines[] = actual.split("\\r?\\n");
		String expectedLines[] = expected.split("\\r?\\n");
		
		
		//assertEquals("Wrong number of lines of results", expectedLines.length, actualLines.length);
		for (int i=0; i < expectedLines.length; i++) {
			String actualCells[] = actualLines[i].split("\\s*,\\s*");
			String expectedCells[] = expectedLines[i].split("\\s*,\\s*");
			
			for (int j=0; j < expectedCells.length; j++) {
				// change any GUIDs to <UUID>
				// so <UUID> may also appear in expected results already 'converted'
				String actualVal = Utility.replaceUUIDs(actualCells[j]);
				String expectedVal = Utility.replaceUUIDs(expectedCells[j]);
				
				// cheap shot at handling dates with and without milliseconds
				if (actualVal.endsWith(".000Z") && !expectedVal.endsWith(".000Z")) {
					expectedVal += ".000Z";
				}
				
				// cheap shot at allowing Neptune to add a URI prefix to belmont/generateSparqlInsert#uri
				if (expectedVal.startsWith("belmont/generateSparqlInsert#")) {
						actualVal = actualVal.replaceFirst("^.*/belmont", "belmont");
				}
				
				if (! actualVal.equals(expectedVal)) {
					fail("At return line " + String.valueOf(i) + " expected val '" + expectedVal + "' did not match actual '" + actualVal + "'");
				}
			}
		}
	}
	
	public static void querySeiAndCheckResults(NodeGroup ng, SparqlEndpointInterface sei, Object caller, String expectedResourceName) throws Exception {
		// get all the answers, changing "\r\n" to simply "\n"
		String query = ng.generateSparql(AutoGeneratedQueryTypes.SELECT_DISTINCT, false, 0, null);		
		Table tab = sei.executeQueryToTable(query);
		String actual = tab.toCSVString();
		IntegrationTestUtility.compareResults(actual, caller, expectedResourceName);
	}
	
	public static void querySeiAndCheckResults(String query, SparqlEndpointInterface sei, Object caller, String expectedResourceName) throws Exception {
		Table tab = sei.executeQueryToTable(query);
		String actual = tab.toCSVString();
		IntegrationTestUtility.compareResults(actual, caller, expectedResourceName);
	}
	
	public static long getStartTime() {
		return System.currentTimeMillis();
	}
	
	public static String logDuration(long startTime, String message) {
		Double dur = (System.currentTimeMillis() - startTime) / 1000.0;
		String entry = message + ": " + String.valueOf(dur) + " sec";
		LocalLogger.logToStdOut(entry);
		return entry;
	}
	
	/**
	 * Called by both OSS and GE tests at some point, so it's here.
	 * @throws Exception
	 */
	public static void setupFdcTests(Class c) throws Exception {
		// skip this file if system is not configured to use the FdcDispatcher
		// TODO: this will get more complicated when there are sub-classes
		assumeTrue("Skipping FDC tests, using non-FDC dispatcher class: " + IntegrationTestUtility.get("integrationtest.dispatcherclassname"), 
				IntegrationTestUtility.get("integrationtest.dispatcherclassname").contains("FdcDispatcher"));
		
		Table servicesFDCConfig = FdcServiceManager.junitGetFdcConfig(IntegrationTestUtility.getServicesSei(),IntegrationTestUtility.getOntologyInfoClient());
		assumeTrue("Skipping FDC _IT tests because services graph doesn't contain FDC Config (e.g. http://research.ge.com/semtk/fdcSample/test#AircraftLocation)",
					Arrays.asList(servicesFDCConfig.getColumn("fdcClass")).contains("http://research.ge.com/semtk/fdcSample/test#AircraftLocation"));
		// setup
		IntegrationTestUtility.authenticateJunit();		
		TestGraph.clearGraph();
		
		// load fdcConfigSample.owl into a local FDC config
		// convert "localhost:12070" placeholder into the location of fdcSampleService
		int port = IntegrationTestUtility.getInt("fdcsampleservice.port");
		String server = IntegrationTestUtility.get("fdcsampleservice.server");
		String configOwl = Utility.getResourceAsString(TestGraph.getOSObject(), "/fdcTestSetup/fdcConfigSample.owl");
		configOwl = configOwl.replace("localhost:12070", server + "/" + String.valueOf(port));
		// rename one nodegroup for nodegroupstore testing
		configOwl = configOwl.replace("fdcSampleElevation", "fdcSampleElevation-STORE");
		
		// first cache will get nothing, but load owl
		FdcServiceManager.cacheFdcConfig(TestGraph.getSei(), IntegrationTestUtility.getOntologyInfoClient());
		// upload fdc config to testGraph
		TestGraph.uploadOwlContents(configOwl);	
		// force re-cache from test graph, different than normal semtk services which FDCDispatcher will use later
		FdcServiceManager.cacheFdcConfig(TestGraph.getSei(), IntegrationTestUtility.getOntologyInfoClient());

		// delete just to be sure
		IntegrationTestUtility.getNodeGroupStoreRestClient().deleteStoredNodeGroupIfExists("fdcSampleDistance");
		IntegrationTestUtility.getNodeGroupStoreRestClient().deleteStoredNodeGroupIfExists("fdcSampleAircraftLocation");
		IntegrationTestUtility.getNodeGroupStoreRestClient().deleteStoredNodeGroupIfExists("fdcSampleElevation");
		IntegrationTestUtility.getNodeGroupStoreRestClient().deleteStoredNodeGroupIfExists("fdcSampleElevation-STORE");

		// load one nodegroup to store
		FdcClient fdcClient = new FdcClient(FdcClientConfig.buildGetNodegroup("http://" + server + ":" + String.valueOf(port) + "/fdcSample/anything", "fdcSampleElevation"));
		SparqlGraphJson sgjson = fdcClient.executeGetNodegroup();
		if (sgjson == null) {
			throw new Exception("Error retrieving fdcSampleElevation nodegroup from fdcSampleService");
		}
		IntegrationTestUtility.getNodeGroupStoreRestClient().executeStoreNodeGroup("fdcSampleElevation-STORE", "no comment", "Junit setupFdcTests", sgjson.toJson());
		
		// ingest FDC owl
		
		TestGraph.uploadOwlResource(c, "/fdcTestSetup/federatedDataConnection.owl");
		TestGraph.uploadOwlResource(c, "/fdcTestSetup/fdcSampleTest.owl");
		
		// ingest a demo aircraft
		String aircraftCsv = "tail,type\ndemo,A320\n";
		TestGraph.ingestCsvString(c, "/fdcTestSetup/fdc_sample_aircraft_ingest_select.json", aircraftCsv);

		// ingest some airports
		TestGraph.ingest(c, "/fdcTestSetup/fdc_ingest_airports.json", "/fdcTestSetup/fdc_airport_lat_lon.csv");
	}
	
	// these are reused in many tests
	public static String getSampleTimeSeriesConstraintJsonStr(){
		return "{\"@var\":\"_Time_\",\"@operator1\":\">=\",\"@value1\":{\"@value\":\"04/07/2016 2:00:00 AM\",\"@type\":\"datetime\"},\"@operator2\":\"<=\",\"@value2\":{\"@value\":\"04/09/2016 4:00:00 AM\",\"@type\":\"datetime\"}}";
	}	
	public static TimeSeriesConstraint getSampleTimeSeriesConstraint() throws Exception{
		return new TimeSeriesConstraint(Utility.getJsonObjectFromString(getSampleTimeSeriesConstraintJsonStr()));
	}	
	public static String getSampleTimeSeriesConstraintQueryFragment_Hive(){
		return "((unix_timestamp(to_utc_timestamp(`ts_time_utc`,'Ect/GMT+0'), 'yyyy-MM-dd HH:mm:ss') >= unix_timestamp('2016-04-07 02:00:00','yyyy-MM-dd HH:mm:ss')) AND (unix_timestamp(to_utc_timestamp(`ts_time_utc`,'Ect/GMT+0'), 'yyyy-MM-dd HH:mm:ss') <= unix_timestamp('2016-04-09 04:00:00','yyyy-MM-dd HH:mm:ss')))";
	}
	
	public static int countSubstring(String str, String findStr) {
		int lastIndex = 0;
		int count = 0;

		while(lastIndex != -1){

		    lastIndex = str.indexOf(findStr,lastIndex);

		    if(lastIndex != -1){
		        count ++;
		        lastIndex += findStr.length();
		    }
		}
		return count;
	}
}
